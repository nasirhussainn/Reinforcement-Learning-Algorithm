{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68ee468",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h2 style=\"color:blue;font-size:30px;\">Artificial Intelligence CS-414</h2>\n",
    "<h3 style=\"color:purple\">Assignment 4</h3>\n",
    " </center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f970a6",
   "metadata": {},
   "source": [
    "<p>Consider Volcano crossing problem discussed in the class. Consider an instance of the problem using different grid size, rewards of end states etc. You are free to define the problem, its states, actions etc. Solve the problem using the following algorithms.</p>\n",
    "<ul style=\"color:purple\">\n",
    "<li>Model free Monte Carlo</li>\n",
    "<li>SARSA</li>\n",
    "<li>Q-Learning</li>\n",
    "</ul>\n",
    "<ol style=\"color:green\">\n",
    "<li>Run the algorithms using different number of episodes of uniformly random policy and show Q-values and average utility.</li>\n",
    "<li>Use different slip probabilities ranging from 0.0 to 0.3 and show your results on different algorithms.</li>\n",
    "<li>Use epsilon greedy algorithms to change generate episode from uniformly random policy for exploration as well as policy that chooses the best action.</li>\n",
    "<li>Write a 2-3 page report and explain your code and results in it.</li>\n",
    "Develop a GUI based user friendly application from which user to choose appropriate options e.g slip probability, epsilon value, no of episodes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae01ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d536303",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">MODEL FREE MONTE CARLO</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80350e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to initialize the environment\n",
    "def initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob):\n",
    "    # Initialize the grid world\n",
    "    grid = np.zeros(grid_size)\n",
    "    \n",
    "    # Set rewards for end states\n",
    "    for state in safe_end_states:\n",
    "        grid[state[0], state[1]] = 20  # Access elements using [row, column]\n",
    "    grid[dangerous_end_state[0], dangerous_end_state[1]] = -50\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b3157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the next state based on the action and slip probability\n",
    "def get_next_state(current_state, action, slip_prob, grid):\n",
    "    # Define possible directions\n",
    "    directions = {\"N\": (-1, 0), \"E\": (0, 1), \"S\": (1, 0), \"W\": (0, -1)}\n",
    "    \n",
    "    # Convert integer action index to string\n",
    "    action_str = list(directions.keys())[action]\n",
    "    \n",
    "    # Check if slip occurs based on slip probability\n",
    "    if np.random.rand() < slip_prob:\n",
    "        # Slip: Move to a random adjacent state\n",
    "        possible_actions = list(directions.keys())\n",
    "        possible_actions.remove(action_str)  # Remove the current action to avoid going back\n",
    "        random_action = np.random.choice(possible_actions)\n",
    "        next_state = tuple(np.array(current_state) + np.array(directions[random_action]))\n",
    "    else:\n",
    "        # No slip: Move in the chosen direction\n",
    "        next_state = tuple(np.array(current_state) + np.array(directions[action_str]))\n",
    "    \n",
    "    # Ensure the next state is within the grid\n",
    "    next_state = (\n",
    "        max(0, min(next_state[0], grid.shape[0] - 1)),\n",
    "        max(0, min(next_state[1], grid.shape[1] - 1))\n",
    "    )\n",
    "    \n",
    "    return next_state\n",
    "\n",
    "# Function to get the reward for a given state\n",
    "def get_reward(state, grid):\n",
    "    # Return the reward for the given state from the grid\n",
    "    return grid[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeb57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform epsilon-greedy action selection\n",
    "def epsilon_greedy(Q, state, epsilon, num_actions):\n",
    "    if np.random.rand() < epsilon:\n",
    "        # Exploration: Choose a random action\n",
    "        return np.random.choice(num_actions)\n",
    "    else:\n",
    "        # Exploitation: Choose the action with the highest Q-value\n",
    "        return np.argmax(Q[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad8b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Monte Carlo sampling with epsilon-greedy exploration\n",
    "def monte_carlo(grid, slip_prob, num_episodes, epsilon):\n",
    "    # Initialize Q-values\n",
    "    Q = np.zeros_like(grid)\n",
    "    returns = np.zeros_like(grid)\n",
    "    visit_count = np.zeros_like(grid)\n",
    "    \n",
    "    # Loop over episodes\n",
    "    for episode in range(num_episodes):\n",
    "        # Initialize the episode\n",
    "        episode_states = []\n",
    "        episode_actions = []\n",
    "        episode_rewards = []\n",
    "    \n",
    "        # Starting state\n",
    "        current_state = (2, 1)\n",
    "    \n",
    "        # Generate an episode using an epsilon-greedy policy\n",
    "        while True:\n",
    "            # Choose action using epsilon-greedy strategy\n",
    "            num_actions = len(Q)  # Total number of possible actions (assuming each state has the same number of actions)\n",
    "            action = epsilon_greedy(Q, current_state, epsilon, num_actions)\n",
    "        \n",
    "            # Store current state and action\n",
    "            episode_states.append(current_state)\n",
    "            episode_actions.append(action)\n",
    "        \n",
    "            # Determine the next state based on the action and slip probability\n",
    "            next_state = get_next_state(current_state, action, slip_prob, grid)\n",
    "        \n",
    "            # Get the reward for the next state\n",
    "            reward = get_reward(next_state, grid)\n",
    "            episode_rewards.append(reward)\n",
    "        \n",
    "            # Update the current state\n",
    "            current_state = next_state\n",
    "        \n",
    "            # Check if the episode has ended\n",
    "            if next_state in [(0, 3), (2, 3)]:\n",
    "                break\n",
    "\n",
    "\n",
    "        \n",
    "        # Update Q-values based on the observed returns\n",
    "        total_return = 0\n",
    "        for t in range(len(episode_states) - 1, -1, -1):\n",
    "            total_return += episode_rewards[t]\n",
    "            \n",
    "            # If the state is not visited before in this episode\n",
    "            if episode_states[t] not in episode_states[:t]:\n",
    "                state = episode_states[t]\n",
    "                action = episode_actions[t]\n",
    "                \n",
    "                # Increment visit count for the state-action pair\n",
    "                visit_count[state] += 1\n",
    "                \n",
    "                # Update Q-value using an incremental formula\n",
    "                Q[state] += (total_return - Q[state]) / visit_count[state]\n",
    "                \n",
    "    # Calculate average utility\n",
    "    average_utility = np.mean(Q)\n",
    "    \n",
    "    return Q, average_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b329bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Slip Probability 0.0 and Epsilon 0.1:\n",
      "Q-values:\n",
      "[[20.         20.         20.          0.        ]\n",
      " [20.         20.         20.         20.        ]\n",
      " [20.         19.86       17.77777778  0.        ]\n",
      " [20.         20.         20.          0.        ]]\n",
      "Average Utility: 16.10236111111111\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.1 and Epsilon 0.1:\n",
      "Q-values:\n",
      "[[19.05970149 19.26238145 19.29149798  0.        ]\n",
      " [18.97810219 19.26624738 18.81556684 13.28767123]\n",
      " [19.16167665 19.23       17.00854701  0.        ]\n",
      " [20.         16.05633803 20.          0.        ]]\n",
      "Average Utility: 14.963608140238424\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.2 and Epsilon 0.1:\n",
      "Q-values:\n",
      "[[ 18.50381679  18.60927152  18.83333333   0.        ]\n",
      " [ 18.75886525  18.40736728  17.68138801  14.06779661]\n",
      " [ 18.68421053  17.34         9.42708333   0.        ]\n",
      " [ 18.67924528  16.41025641  -5.2        -50.        ]]\n",
      "Average Utility: 9.38766464718444\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.3 and Epsilon 0.1:\n",
      "Q-values:\n",
      "[[ 16.752       16.6589057   17.10869565   0.        ]\n",
      " [ 16.97297297  15.97065463  14.91097923   8.01369863]\n",
      " [ 16.81818182  14.4          6.35782748   0.        ]\n",
      " [ 15.51282051  13.16091954   1.19402985 -36.        ]]\n",
      "Average Utility: 8.614480375852136\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to run experiments with different slip probabilities and epsilon values\n",
    "def run_experiments():\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    num_episodes = 1000  # Adjust as needed\n",
    "    \n",
    "    slip_probabilities = [0.0, 0.1, 0.2, 0.3]\n",
    "    epsilon_values = [0.1]  # Adjust as needed\n",
    "    \n",
    "    for slip_prob in slip_probabilities:\n",
    "        for epsilon in epsilon_values:\n",
    "            # Initialize the environment\n",
    "            grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob)\n",
    "            \n",
    "            # Run Monte Carlo algorithm with epsilon-greedy exploration\n",
    "            Q_values, avg_utility = monte_carlo(grid, slip_prob, num_episodes, epsilon)\n",
    "            \n",
    "            # Display results for each slip probability and epsilon value\n",
    "            print(f\"Results for Slip Probability {slip_prob} and Epsilon {epsilon}:\")\n",
    "            print(\"Q-values:\")\n",
    "            print(Q_values)\n",
    "            print(f\"Average Utility: {avg_utility}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "# Main function to run experiments\n",
    "def main():\n",
    "    run_experiments()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d3d6e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">SARSA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba15f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform SARSA with epsilon-greedy exploration\n",
    "def sarsa(grid, slip_prob, num_episodes, epsilon, alpha, gamma):\n",
    "    # Initialize Q-values\n",
    "    Q = np.zeros(grid.shape + (4,))  # Separate Q array for each state-action pair\n",
    "    \n",
    "    # Loop over episodes\n",
    "    for episode in range(num_episodes):\n",
    "        # Starting state\n",
    "        current_state = (2, 1)\n",
    "        \n",
    "        # Choose action using epsilon-greedy strategy\n",
    "        num_actions = Q.shape[2]\n",
    "        current_action = epsilon_greedy(Q, current_state, epsilon, num_actions)\n",
    "        \n",
    "        # Initialize flag for episode completion\n",
    "        episode_complete = False\n",
    "        \n",
    "        while not episode_complete:\n",
    "            # Determine the next state based on the action and slip probability\n",
    "            next_state = get_next_state(current_state, current_action, slip_prob, grid)\n",
    "            \n",
    "            # Get the reward for the next state\n",
    "            reward = get_reward(next_state, grid)\n",
    "            \n",
    "            # Choose next action using epsilon-greedy strategy\n",
    "            next_action = epsilon_greedy(Q, next_state, epsilon, num_actions)\n",
    "            \n",
    "            # Update Q-value using the SARSA update rule\n",
    "            Q[current_state + (current_action,)] += alpha * (reward + gamma * Q[next_state + (next_action,)] - Q[current_state + (current_action,)])\n",
    "            \n",
    "            # Update current state and action\n",
    "            current_state = next_state\n",
    "            current_action = next_action\n",
    "            \n",
    "            # Check if the episode has ended\n",
    "            episode_complete = next_state in [(0, 3), (2, 3)]\n",
    "    \n",
    "    # Calculate average utility\n",
    "    average_utility = np.mean(Q)\n",
    "    \n",
    "    return Q, average_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce6fb03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Slip Probability 0.0, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 0.         15.3952904   0.8649457   1.16898189]\n",
      "  [14.10473839 17.66840659 11.08395535 11.48915468]\n",
      "  [16.65557727 20.         13.29291439 14.28995138]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[10.37943526  0.          0.95779768  0.52032741]\n",
      "  [15.07069906  9.60641951 10.89873532  6.00772044]\n",
      "  [17.12346342  0.504       2.33968775  1.38009835]\n",
      "  [ 5.42        0.          0.          0.        ]]\n",
      "\n",
      " [[ 1.91938916  7.82819427  0.          0.        ]\n",
      "  [13.56648855  8.58297164  7.22784837  2.92279226]\n",
      "  [12.20811227  0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          1.44875385  0.          0.        ]\n",
      "  [10.62560327  0.02139837  0.          0.06112863]\n",
      "  [ 0.5414789   0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "Average Utility: 4.424632184263154\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.1, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 4.5809479  14.27368523  2.93850582  5.38161845]\n",
      "  [13.83991962 16.69805241 11.20203939  9.33371237]\n",
      "  [15.27051744 19.7990226  13.27866424 13.12913689]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[11.79510554  7.2205028   1.80937601  0.76135302]\n",
      "  [14.65984781 13.33670715 10.66629535  8.26949188]\n",
      "  [16.69592806  1.0054062   1.60157955  5.05023532]\n",
      "  [13.72378808  0.          0.          0.        ]]\n",
      "\n",
      " [[10.06327904  3.07313719  0.127064    0.60350017]\n",
      "  [12.79754007  9.13812489  6.78177679  7.85665425]\n",
      "  [13.31904828 -5.          0.2551843  -6.92694492]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 1.97930073  0.56776119  0.          0.11550118]\n",
      "  [10.1078541   0.09897068  1.27641198  0.03840283]\n",
      "  [ 5.77225664  0.          0.          0.        ]\n",
      "  [-5.          0.          0.          0.        ]]]\n",
      "Average Utility: 4.896347851811532\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.2, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[  7.19215817  13.71801848   3.87434245   5.83244687]\n",
      "  [ 13.76749736  16.68492342  11.96431251  10.31074056]\n",
      "  [ 15.63675562  19.56015693  12.31895473  13.1335529 ]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[ 11.80990914   7.17045419   3.11195391   3.89029958]\n",
      "  [ 13.71928132   9.74258465   7.45634617   9.2440966 ]\n",
      "  [ 14.29109391   0.53335824   2.12511107   5.85262916]\n",
      "  [  3.93155891  -3.30533573  -4.46800653  -2.57151353]]\n",
      "\n",
      " [[  9.39319259   2.19841078   0.03274759   1.60262567]\n",
      "  [ 10.98262364   2.40529007   5.63487881   6.09299425]\n",
      "  [ -5.72846752 -20.4755       3.95665299  -4.82100177]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  6.15494554   0.           0.06660467   0.        ]\n",
      "  [  8.081651     0.68627339   1.8452932    2.43993823]\n",
      "  [  0.204312    -0.43755425   0.94365483   4.04027544]\n",
      "  [ -9.5         -9.23666067  -9.32268205  -9.50848286]]]\n",
      "Average Utility: 3.5040577595385747\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.3, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[  5.31097071   7.80823384   7.63648537   1.36775377]\n",
      "  [  9.22000303  15.04725728   9.92273426   7.65771275]\n",
      "  [ 14.03443543  19.03444389  12.13241774  12.11610548]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  4.91748417   9.9443226    5.10664987   7.19433326]\n",
      "  [ 11.75221569   9.27114811   7.43941485   8.19943569]\n",
      "  [ 13.93969407   6.70972091   1.77852414   8.93892496]\n",
      "  [ 10.08692973   6.23757412   2.          -3.34239381]]\n",
      "\n",
      " [[  7.41434448   2.01378657   3.91580347   5.3370688 ]\n",
      "  [  9.97015741   5.81229791   4.71686068   6.22536095]\n",
      "  [ 11.62410801 -18.43660636  -7.88536387  -9.51642076]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  5.64122501   2.2012216    2.69795904   1.37503939]\n",
      "  [  1.28553344   1.36179105   0.86140837   5.35610217]\n",
      "  [ -1.78745751  -2.55248398  -1.95439552   2.45830124]\n",
      "  [ -9.28357572  -9.26797008  -8.65179858  -2.09214436]]]\n",
      "Average Utility: 3.754729449680376\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to run experiments with different slip probabilities, epsilon values, alpha, and gamma\n",
    "def run_sarsa_experiments():\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    num_episodes = 1000  # Adjust as needed\n",
    "    \n",
    "    slip_probabilities = [0.0, 0.1, 0.2, 0.3]\n",
    "    epsilon_values = [0.1]  # Adjust as needed\n",
    "    alpha_values = [0.1]  # Learning rate\n",
    "    gamma_values = [0.9]  # Discount factor\n",
    "    \n",
    "    for slip_prob in slip_probabilities:\n",
    "        for epsilon in epsilon_values:\n",
    "            for alpha in alpha_values:\n",
    "                for gamma in gamma_values:\n",
    "                    # Initialize the environment\n",
    "                    grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob)\n",
    "                    \n",
    "                    # Run SARSA algorithm with epsilon-greedy exploration\n",
    "                    Q_values, avg_utility = sarsa(grid, slip_prob, num_episodes, epsilon, alpha, gamma)\n",
    "                    \n",
    "                    # Display results for each combination of parameters\n",
    "                    print(f\"Results for Slip Probability {slip_prob}, Epsilon {epsilon}, Alpha {alpha}, Gamma {gamma}:\")\n",
    "                    print(\"Q-values:\")\n",
    "                    print(Q_values)\n",
    "                    print(f\"Average Utility: {avg_utility}\")\n",
    "                    print(\"\\n\")\n",
    "\n",
    "# Main function to run SARSA experiments\n",
    "def main_sarsa():\n",
    "    run_sarsa_experiments()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_sarsa()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ce641",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">Q LEARNING</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5813d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Q-learning with epsilon-greedy exploration\n",
    "def q_learning(grid, slip_prob, num_episodes, epsilon, alpha, gamma):\n",
    "    # Initialize Q-values\n",
    "    Q = np.zeros(grid.shape + (4,))  # Separate Q array for each state-action pair\n",
    "    \n",
    "    # Loop over episodes\n",
    "    for episode in range(num_episodes):\n",
    "        # Starting state\n",
    "        current_state = (2, 1)\n",
    "        \n",
    "        # Initialize flag for episode completion\n",
    "        episode_complete = False\n",
    "        \n",
    "        while not episode_complete:\n",
    "            # Choose action using epsilon-greedy strategy\n",
    "            num_actions = Q.shape[2]\n",
    "            current_action = epsilon_greedy(Q, current_state, epsilon, num_actions)\n",
    "            \n",
    "            # Determine the next state based on the action and slip probability\n",
    "            next_state = get_next_state(current_state, current_action, slip_prob, grid)\n",
    "            \n",
    "            # Get the reward for the next state\n",
    "            reward = get_reward(next_state, grid)\n",
    "            \n",
    "            # Update Q-value using the Q-learning update rule\n",
    "            Q[current_state + (current_action,)] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[current_state + (current_action,)])\n",
    "            \n",
    "            # Update current state\n",
    "            current_state = next_state\n",
    "            \n",
    "            # Check if the episode has ended\n",
    "            episode_complete = next_state in [(0, 3), (2, 3)]\n",
    "    \n",
    "    # Calculate average utility\n",
    "    average_utility = np.mean(Q)\n",
    "    \n",
    "    return Q, average_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3552db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Slip Probability 0.0, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 1.43554257 16.16966334  1.42935663  2.17522747]\n",
      "  [15.35178506 18.         13.51443224 12.21597405]\n",
      "  [16.22741087 20.         14.0269638  14.23028215]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[13.94372498  0.          0.          0.        ]\n",
      "  [16.2        13.45566717 11.94633964 10.72090542]\n",
      "  [17.98256613  0.18        0.95297645  0.        ]\n",
      "  [ 3.8         0.          0.          0.        ]]\n",
      "\n",
      " [[ 2.08463962 10.12010729  0.          0.62320112]\n",
      "  [14.58        9.23638977  7.34422099  4.99661602]\n",
      "  [14.3451499   0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.08343709  0.          0.          0.        ]\n",
      "  [11.52994563  0.          0.9625912   0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "Average Utility: 4.841642446774151\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.1, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 5.63346036 15.09986407  4.03937695  2.59952222]\n",
      "  [15.0314259  16.88990367 13.47346202 13.18148732]\n",
      "  [16.82708321 19.57741746 14.82082103 15.04793737]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[13.66594288  4.4213522   2.03412419  5.73722096]\n",
      "  [15.16542656 13.06519873 11.02890456  7.94950784]\n",
      "  [16.81693084  2.86581595  4.29311273  4.18779217]\n",
      "  [11.3906558   0.          0.          0.        ]]\n",
      "\n",
      " [[12.1229339   2.03318155  0.04640202  0.        ]\n",
      "  [13.43074025 11.22355195  8.53327392  8.68751184]\n",
      "  [15.40960059 -5.          0.13315411  3.14756454]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 3.27427844  0.          0.          0.        ]\n",
      "  [10.81063943  0.20590622  1.00993577  0.23606367]\n",
      "  [ 5.32127452  0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "Average Utility: 5.55421499552328\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.2, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[  6.0485554   14.38971816   7.19838134   7.0487923 ]\n",
      "  [ 14.23342281  15.82717694  12.30738283  12.78290036]\n",
      "  [ 16.34841072  19.07838502  14.46459943  15.22690407]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[ 12.7929857    3.2865367    3.68918947   5.23501717]\n",
      "  [ 14.2856316   12.71567166   9.4498936   10.76432231]\n",
      "  [ 15.76292763   5.89208723   6.78960743   6.35181947]\n",
      "  [  7.56586521  -3.60936919   0.           0.        ]]\n",
      "\n",
      " [[  2.45007903  10.5166649    2.90488999   3.16111594]\n",
      "  [ 11.72137669   6.52507652   8.14380314   9.16168486]\n",
      "  [  4.7491419  -20.4755      -0.34231995   1.95132618]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  7.40596253   0.67177289   0.           0.60178346]\n",
      "  [  9.71368969   0.           0.91721034   1.37874712]\n",
      "  [  4.87314106   0.           0.41317933   0.        ]\n",
      "  [ -5.          -5.          -5.           0.        ]]]\n",
      "Average Utility: 4.9589006406926694\n",
      "\n",
      "\n",
      "Results for Slip Probability 0.3, Epsilon 0.1, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[  8.57288909  12.60834026   8.10943135   8.17621439]\n",
      "  [ 13.18378068  15.70159396  12.21026362  11.68543584]\n",
      "  [ 15.84734906  18.98278278  13.84483107  14.01097165]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[ 11.09037784   8.55509052   6.30735336   7.00509668]\n",
      "  [ 12.80386561  11.15036286   8.05494033   9.03841283]\n",
      "  [ 14.93931129   6.24270535   5.91223354   6.28071386]\n",
      "  [ 17.34867679   0.47264433  -9.5         -3.36012088]]\n",
      "\n",
      " [[  9.60198447   2.98695162   3.15870945   4.10908557]\n",
      "  [  9.61567271   4.26597192   6.33255529   5.70879624]\n",
      "  [  8.41075772 -22.63540512  -5.38331505  -8.60829079]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  7.63596523   1.1567008    0.68839366   0.68608916]\n",
      "  [  8.02349698   2.48239098   3.84961698   2.47248245]\n",
      "  [  0.87817569  -0.15918533   0.65967819   5.33554946]\n",
      "  [ -5.           0.           0.45990176  -3.68345429]]]\n",
      "Average Utility: 4.817575372220121\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to run experiments with different slip probabilities, epsilon values, alpha, and gamma\n",
    "def run_q_learning_experiments():\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    num_episodes = 1000  # Adjust as needed\n",
    "    \n",
    "    slip_probabilities = [0.0, 0.1, 0.2, 0.3]\n",
    "    epsilon_values = [0.1]  # Adjust as needed\n",
    "    alpha_values = [0.1]  # Learning rate\n",
    "    gamma_values = [0.9]  # Discount factor\n",
    "    \n",
    "    for slip_prob in slip_probabilities:\n",
    "        for epsilon in epsilon_values:\n",
    "            for alpha in alpha_values:\n",
    "                for gamma in gamma_values:\n",
    "                    # Initialize the environment\n",
    "                    grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob)\n",
    "                    \n",
    "                    # Run Q-learning algorithm with epsilon-greedy exploration\n",
    "                    Q_values, avg_utility = q_learning(grid, slip_prob, num_episodes, epsilon, alpha, gamma)\n",
    "                    \n",
    "                    # Display results for each combination of parameters\n",
    "                    print(f\"Results for Slip Probability {slip_prob}, Epsilon {epsilon}, Alpha {alpha}, Gamma {gamma}:\")\n",
    "                    print(\"Q-values:\")\n",
    "                    print(Q_values)\n",
    "                    print(f\"Average Utility: {avg_utility}\")\n",
    "                    print(\"\\n\")\n",
    "\n",
    "# Main function to run Q-learning experiments\n",
    "def main_q_learning():\n",
    "    run_q_learning_experiments()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_q_learning()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb961ee",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3 style=\"color:purple\">GUI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821eacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run experiments with different slip probabilities and epsilon values\n",
    "def run_experiments(slip_prob, epsilon, num_episodes):\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    \n",
    "    if not isinstance(slip_prob, (list, tuple)):\n",
    "        slip_prob = [slip_prob]\n",
    "    \n",
    "    if not isinstance(epsilon, (list, tuple)):\n",
    "        epsilon = [epsilon]\n",
    "    \n",
    "    for slip_prob_val in slip_prob:\n",
    "        for epsilon_val in epsilon:\n",
    "            # Initialize the environment\n",
    "            grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob_val)\n",
    "            \n",
    "            # Run Monte Carlo algorithm with epsilon-greedy exploration\n",
    "            Q_values, avg_utility = monte_carlo(grid, slip_prob_val, num_episodes, epsilon_val)\n",
    "            \n",
    "            # Display results for each slip probability and epsilon value\n",
    "            print(\"MONTO CARLO FREE MODEL\")\n",
    "            print(f\"Results for Slip Probability {slip_prob_val} and Epsilon {epsilon_val}:\")\n",
    "            print(\"Q-values:\")\n",
    "            print(Q_values)\n",
    "            print(f\"Average Utility: {avg_utility}\")\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0252d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run experiments with different slip probabilities, epsilon values, alpha, and gamma\n",
    "def run_sarsa_experiments(slip_probabilities, epsilon_values, num_episodes):\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    alpha_values = [0.1]  # Learning rate\n",
    "    gamma_values = [0.9]  # Discount factor\n",
    "    \n",
    "    if not isinstance(slip_probabilities, (list, tuple)):\n",
    "        slip_probabilities = [slip_probabilities]\n",
    "    \n",
    "    if not isinstance(epsilon_values, (list, tuple)):\n",
    "        epsilon_values = [epsilon_values]\n",
    "    \n",
    "    if not isinstance(alpha_values, (list, tuple)):\n",
    "        alpha_values = [alpha_values]\n",
    "    \n",
    "    if not isinstance(gamma_values, (list, tuple)):\n",
    "        gamma_values = [gamma_values]\n",
    "    \n",
    "    for slip_prob in slip_probabilities:\n",
    "        for epsilon in epsilon_values:\n",
    "            for alpha in alpha_values:\n",
    "                for gamma in gamma_values:\n",
    "                    # Initialize the environment\n",
    "                    grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob)\n",
    "                    \n",
    "                    # Run SARSA algorithm with epsilon-greedy exploration\n",
    "                    Q_values, avg_utility = sarsa(grid, slip_prob, num_episodes, epsilon, alpha, gamma)\n",
    "                    \n",
    "                    # Display results for each combination of parameters\n",
    "                    print(\"SARSA\")\n",
    "                    print(f\"Results for Slip Probability {slip_prob}, Epsilon {epsilon}, Alpha {alpha}, Gamma {gamma}:\")\n",
    "                    print(\"Q-values:\")\n",
    "                    print(Q_values)\n",
    "                    print(f\"Average Utility: {avg_utility}\")\n",
    "                    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd2ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run experiments with different slip probabilities, epsilon values, alpha, and gamma\n",
    "def run_q_learning_experiments(slip_probabilities, epsilon_values, num_episodes):\n",
    "    grid_size = (4, 4)\n",
    "    start_state = (2, 1)\n",
    "    safe_end_states = [(0, 3), (2, 3)]  # Valid column indices are 0, 1, 2, 3\n",
    "    dangerous_end_state = (2, 3)  # Assuming this is meant to be a dangerous state\n",
    "    \n",
    "    alpha_values = [0.1]  # Learning rate\n",
    "    gamma_values = [0.9]  # Discount factor\n",
    "    \n",
    "    if not isinstance(slip_probabilities, (list, tuple)):\n",
    "        slip_probabilities = [slip_probabilities]\n",
    "    \n",
    "    if not isinstance(epsilon_values, (list, tuple)):\n",
    "        epsilon_values = [epsilon_values]\n",
    "    \n",
    "    if not isinstance(alpha_values, (list, tuple)):\n",
    "        alpha_values = [alpha_values]\n",
    "    \n",
    "    if not isinstance(gamma_values, (list, tuple)):\n",
    "        gamma_values = [gamma_values]\n",
    "    \n",
    "    for slip_prob in slip_probabilities:\n",
    "        for epsilon in epsilon_values:\n",
    "            for alpha in alpha_values:\n",
    "                for gamma in gamma_values:\n",
    "                    # Initialize the environment\n",
    "                    grid = initialize_environment(grid_size, start_state, safe_end_states, dangerous_end_state, slip_prob)\n",
    "                    \n",
    "                    # Run Q-learning algorithm with epsilon-greedy exploration\n",
    "                    Q_values, avg_utility = q_learning(grid, slip_prob, num_episodes, epsilon, alpha, gamma)\n",
    "                    \n",
    "                    # Display results for each combination of parameters\n",
    "                    print(\"Q LEARNING\")\n",
    "                    print(f\"Results for Slip Probability {slip_prob}, Epsilon {epsilon}, Alpha {alpha}, Gamma {gamma}:\")\n",
    "                    print(\"Q-values:\")\n",
    "                    print(Q_values)\n",
    "                    print(f\"Average Utility: {avg_utility}\")\n",
    "                    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1beb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTO CARLO FREE MODEL\n",
      "Results for Slip Probability 0.2 and Epsilon 0.3:\n",
      "Q-values:\n",
      "[[ 15.90425532  16.09970674  16.50623886   0.        ]\n",
      " [ 15.74814815  15.52631579  14.63443396   9.67741935]\n",
      " [ 14.81481481  13.68292683   4.2278481    0.        ]\n",
      " [ 15.81196581  12.25409836  -0.68181818 -39.23076923]]\n",
      "Average Utility: 7.810974042706549\n",
      "\n",
      "\n",
      "SARSA\n",
      "Results for Slip Probability 0.2, Epsilon 0.3, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 9.87672514e+00  1.26704629e+01  8.80203200e+00  1.01544024e+01]\n",
      "  [ 1.19507279e+01  1.45686707e+01  1.03045423e+01  1.04854352e+01]\n",
      "  [ 1.55549285e+01  1.82153099e+01  1.14690914e+01  1.26028510e+01]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.02488890e+01  9.55370256e+00  6.99867132e+00  8.77838676e+00]\n",
      "  [ 1.20101695e+01  9.86455239e+00  6.44437742e+00  8.63970053e+00]\n",
      "  [ 1.28492388e+01  1.10202225e+01  4.12339922e-01  8.78122879e+00]\n",
      "  [ 1.86168852e+01  6.41037541e+00 -1.61217897e+01  5.05855768e+00]]\n",
      "\n",
      " [[ 8.34434314e+00  5.59982271e+00  5.38914280e+00  6.13192485e+00]\n",
      "  [ 2.51843366e+00 -8.49400486e-01  3.33601111e+00  5.96515856e+00]\n",
      "  [ 4.23526229e+00 -4.26878070e+01 -8.47477913e+00 -3.08291655e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.17919315e+00  3.09693605e+00  3.61904384e+00  3.47403759e+00]\n",
      "  [ 3.14093723e+00  2.24140883e+00  2.49523704e+00  4.47549999e+00]\n",
      "  [-2.34938738e-01 -2.53474219e-01  1.10266806e+00  2.88885471e+00]\n",
      "  [-1.20957513e+01  1.11185425e-03 -9.79785580e-01  1.03415843e+00]]]\n",
      "Average Utility: 4.262984693484665\n",
      "\n",
      "\n",
      "Q LEARNING\n",
      "Results for Slip Probability 0.2, Epsilon 0.3, Alpha 0.1, Gamma 0.9:\n",
      "Q-values:\n",
      "[[[ 12.9729133   13.92466004  11.84067456  12.70933982]\n",
      "  [ 14.45856201  16.33922905  13.7146963   12.8706926 ]\n",
      "  [ 17.18759651  19.55334551  15.56218047  15.81956535]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[ 12.1721926   12.42047914   9.67334944  10.77612071]\n",
      "  [ 14.45291123  13.97747914  11.32842852  11.43019877]\n",
      "  [ 14.60753854   7.49501946   7.0376436   11.67232912]\n",
      "  [  7.11864383   0.53760955 -10.20288184  -3.0941171 ]]\n",
      "\n",
      " [[ 10.85815621   9.51517567   8.17505878   9.31681631]\n",
      "  [ 12.81910204   9.16431817   9.25569278   9.60053919]\n",
      "  [ 12.72463515 -31.81040556   2.59536104   0.58906261]\n",
      "  [  0.           0.           0.           0.        ]]\n",
      "\n",
      " [[  9.4649579    6.38582846   5.89801067   6.13059033]\n",
      "  [ 10.36804442   6.62390928   8.37821537   7.16910904]\n",
      "  [  4.82830205   0.18996405   4.92360206   8.94985763]\n",
      "  [-13.55        -6.57775268  -5.          -0.25701869]]]\n",
      "Average Utility: 6.641961445367782\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from functools import partial\n",
    "def on_run_button_click(slip_prob_entry, epsilon_entry, num_episodes_entry):\n",
    "    slip_prob = float(slip_prob_entry.get())\n",
    "    epsilon = float(epsilon_entry.get())\n",
    "    num_episodes = int(num_episodes_entry.get())\n",
    "\n",
    "    run_experiments(slip_prob, epsilon, num_episodes)\n",
    "    run_sarsa_experiments(slip_prob, epsilon, num_episodes)\n",
    "    run_q_learning_experiments(slip_prob, epsilon, num_episodes)\n",
    "\n",
    "\n",
    "def create_gui():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Reinforcement Learning Experiments\")\n",
    "\n",
    "    # Create labels and entry fields\n",
    "    tk.Label(root, text=\"Slip Probability:\").grid(row=0, column=0, padx=10, pady=5)\n",
    "    slip_prob_entry = tk.Entry(root)\n",
    "    slip_prob_entry.grid(row=0, column=1, padx=10, pady=5)\n",
    "\n",
    "    tk.Label(root, text=\"Epsilon Value:\").grid(row=1, column=0, padx=10, pady=5)\n",
    "    epsilon_entry = tk.Entry(root)\n",
    "    epsilon_entry.grid(row=1, column=1, padx=10, pady=5)\n",
    "\n",
    "    tk.Label(root, text=\"Number of Episodes:\").grid(row=2, column=0, padx=10, pady=5)\n",
    "    num_episodes_entry = tk.Entry(root)\n",
    "    num_episodes_entry.grid(row=2, column=1, padx=10, pady=5)\n",
    "\n",
    "    run_button = tk.Button(root, text=\"Run Experiments\", command=partial(on_run_button_click, slip_prob_entry, epsilon_entry, num_episodes_entry))\n",
    "    run_button.grid(row=3, column=0, columnspan=2, pady=10)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "create_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadfad9",
   "metadata": {},
   "source": [
    "<h3 style=\"color:purple\">Submitted By</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1ee8b",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> Nasir Hussain</li>\n",
    "<li> Laiba Masood</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbfbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
